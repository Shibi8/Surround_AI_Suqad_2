![](data:image/*;base64,iVBORw0KGgoAAAANSUhEUgAAATsAAABPCAMAAAHUwaIAAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAKCUExURQAAAP///wAAAIAAAFUAAIAAQIArK5IkJJJtbZKSkoAAIJ8gQI4cOY6OjpkaM5UVQJ0UO4giM5kiM5yqqpkmQJIkPZ6enpAhN5umsZ8gQJ8rQKenp5skQJylpZ6epZ6lpZyjqp+lpZkmQJIkPZ2jqJwkPpkkPZkpQqGlpZspQJ2mppooPpglQqClqZcoQJYmP6GkqJgpQZcmQqOjqZgnQJ+lpZcnQJcoQKClqponQJ+mqKKnp6GmppkpP56lp6Clp6OnqZkpQZgpPpopPpkqP5knPp+lqZgmQZkqQKGjp6GlqZcoQpcpQZkpQKGnp6CmqaGmqKGjqaGkqJkqQJ+kqJoqQJkmP5kqP5cnQqGmqZgpQJkqQpgoQJooQpoqQaGmqaClp5+kqZoqQJkoQJgpP6CmqJ+mp5gnQKCmqKGkqpkpQJoqPpgpP5gpQpkpQaCmqZksQqCkqKGmqJgpP6Clp5knP6CmqaClqZgqQaCmqKCkqKGlqJkpQKClqJ+lqKCkp5cnQJonQqCmqKClqJkpQJkpQZopQaClqKGmqZkpQZkqQaClqJoqQposRJotRJouRZovRpoySJozSZo4TppGWJs/U5s/VJtCVptFWJtaapxZaZxba5xcbJxebZxhcJxjcZxqdp1ZaJ1lc51odp1seZ1ue51yfp1zfp1zf543TJ57hp58hp59h56EjZ6Hj56OlJ6SmJ+Hj5+OlZ+UmaCYnqCboKCfo6ChpKChpaCipaCipqCkp6CkqKClqKGjpqGlqKGmqamZoLKFkLW4u7arsbehqcrNz9nKzt24wODi4+Xm5+nq6+vW2vHy8/Pz8/jx8/n5+fn6+vv6+/38/P7+/v///1EjS8EAAACMdFJOUwABAgIDBAYHBwcICAkJCgwNDw8SFBUVFxcYGBocHyIiJCUoKi8xMjI2ODk6Pj5ASUlKUVNUVVtgZmhqa21xcXR0dnd3ent9fn9/f4CChIWGh4iSk5WXmZmbnqOqq6usrrO0tre5v8DCwsXGyM3S09PW1tfZ2+Lm6evu7+/w8/X5+vr6+/z8/f39/v7+pnTV/gAAAAlwSFlzAAAh1QAAIdUBBJy0nQAAB2NJREFUaEPtmoW/3EQQx4MWKFDc3d3d3d3d3d3doSkuD4fS4u5WCO7O+38Y+e1uksvmNqd5R76fvsvOzM7sbye5u9z1ojxJzMAoZf84Ho/jTWEVEcdJEifRrjTxzzhejUwE8tCCO0c6MY6ns+mBIhyjicTU0okSo4kw5VCAq2hMepBhDkR2C5k4P+1UBehE78arEHxmqIvURhgF0DlJPmFVMo9PkUcey3bz/LugAIfk7HGKd55eAUZb+3rWLEbmnREwj86x7CNj9h45QdwrAq5KSCJgWy7z8fHxMXHwAx+rQPOlKYvKwdT7lo/kMNFwkEd/6Xp8YBuHCkiGzZJ6L7yXEGJ3Vu9Cfs0RpJ4Ohc7q0SP/keWvF1rXZsjhOl+9+EM5tIMbZYlmGgqjw0dfv4S74eoSLoXLD57uQL1OCy7MeUAcPDD17O4lEobk8NnDdcGmrWejMjWM4yWRKKon5kHsD+ZYTSR89SQYDOrpP1uPD7xNPsq0YLQeJKLej/woXeOBBkKReqtm6j31Kp8gK1f8wXA9Il3PjAk2MQxE9NmXvx7Vw8kgelmP/7z1jkt5y0C96ym3tF7aW8Z5poAefPUy3jI442FXh4+zNMKwuZUew+rJlWaYC6/2M18sisL3v4K2zS0V8LIh7IL48DkTiuRV0im8GeFhI/c3jMpzHUS8z6TPXwp7Lefl/QSTZ7jU+/p4+Z+iSyTJtjseePTZqtculpf3O0zMyBj9wbyduCU28cuDlZcnc/tDRp6u5JX3LywzwVhi9IecPDl45GFMkxA3tlp9IS3PqLRYeZZp/DQwk+AbgDzgkyeihBURYkwQZj+w3cs+ZxUnD44spcHeEHZyayHPPmfNu0In8nqrNiMPz9ktjdmBPDIvxrAXnIAlUmvE8RuwDtVgBXk5s2t0hfgLW5QtI1ZCTKA8sXomb9KRUr4VXmKxrWEoxywzCVnK5OUQyNM7eXLLUsjKUXQShimQpMBXACY01JckuRdXUwZEhw1dQ+9DEd+v/I1hbfS5lxW5m7K3UwgOHcjJ3ykjOmygJq+uJvIgxqhzt8qI9xWs1QLCfnUzWnKR0FOKP9+61sBuUUcz6CmNMb1/9ek9wi4hKxBqIFqmzqV+JInI6DFYgj5873HYidcmySw2ECtVF0X7YZysJZP7ga7gBEXTg9WtjbHL7Tm6QkodedqqU0FrpI3+oCtA0Bbq8an7BeaQ1I3Jo1cdrPjNoajba0wObjkEoe47WEbPgNXFqs7+d0JW3SswSM5Q1VkQjP8Y/wcj0YZZg1UXe9U5WJuZNFB19OhT9/zTL7/zqQgjrkFwgOoUnzroYhBh6qMOjgwDPLPypl5bdWexvNqqk/Hoq+vpbbKuoOo2M+rO10Mn6uKXTseoF+gKqi6CutuTqXLsSF3x3A7RFaAOle0KCNZEnb7/n9uFOt/cDtEVjDrBrYCgZ8U1W4Pr9V0dW0HqNm4Neud2iK7g1N0j1o1qSIgoXhHBJ12QzV6qm08WIMTC2GiFRZSpix9X81K1khXU7JrDL9eCeWaRmCmrwACrT0ESmOz9VhwTukdvigqIou3xsxNHdllMLAATugf1WimOaRKArxXEGxoa8uhThL9wC+MO5DWA2S8x35A65GsP5ms4HMhqAHJbkQadE+ByIKlBOAJdsaBtyvdwWuZBWgOxO5piQdfAN/Ba3l0WiROfRaqBrBT2hzcGNM0Ar2OE7sHozfIx7CqA1n23691XcDvMze+jsNM8K+/eE6a7IhbSgbgMH6R/e0E20gztevcb3I4kWSeK1pfa8BjEp6D6ROACqFegP8UzLoIMQ7ve/QW3I1XjJrgUWekuhCYO+LEeaO3QSrhGWiPtevcz3I5UjQ3gUrh1CEwk8r8BLtpDcaRd756A2zIjVQNfEQIKzIvARCKkd9y86r2D10El/L2Df0Lh7118DgZRtGQHvXsQXgu3bgnkjnzvxpxRvXfwObh1VyN11HvH/zHprFtbt1fWux/gslB6klyGTGKke0dP03Tv+G4QA4O3d7/CtjzAjUuSjZDIjHTvyMj2roWW3hXzNreNQZoywr0To9vevc4dAzsgyTCSvft4Qwyr906aVMB2SEgzgr3L0G3v9sbEIkbzOZt8Pg1GB71DqD0j2jtGjKZ3bSh+r4j2IaPpXRs8vYvmaHrXFl/vcp8rChhQ7/aML1oKw7rh7Z18nk1vKV4cAzCg3sXxl0lyMIx6Edw7Caa3OJjeaTS88CDx9y46OW1p8E5YzEB6h+g2MOtFSe+i6IbNMeA9PJIL7qspjj70rjw6bE4TeQaPTBPLBE8Vb4oqe1wXOYovU4KvVak7UG4TfYYimXO7WCYIt6PKHo9CjvJZYSaC+XXrAwQacjLnhJuhLewEtwC34/4Ke0SKIUmWR8CAAEHrHgJnrVga+gJ4K3v64c3y3AKItgPzg6jfZbcQlAVDW+A9LAizjKt0iUIwJZyH6tc78/vNKtwSniczC8GESiC1ThxQEaRdiR2VgrkFzIYZ4VyBzIaGhv8VUfQfl5Fh+79yefEAAAAASUVORK5CYII=)

1.
  1. **Overview of the Example:**

This example contains the data from the last 14 years(2006/07 to 2018/19) of the English Premire League. Data contains certain features and it is filtered further. Example epl contains SurroundData type object which has the prcoessed data in it. That data is splitted into train and test data which is then predicted using the Logistic Regression. The prediction result and it&#39;s analysis is then displayed and saved in the output directory.

![](https://raw.githubusercontent.com/Shibi8/Surround\_AI\_Suqad\_2/master/epl/docs/epl\_flow\_diagram.png)

1.
  1. **Creating the Project:**

From the project&#39;s local folder:

python3 \_\_main\_\_.p

1.
  1. **Data Selection: Epl.csv**
    1. **Source:**

The Data utilized in this example has been utilized from the [http://www.football-data.co.uk/englandm.php](http://www.football-data.co.uk/englandm.php) website which provides the data for different periods.

1.
  1.
    1. **Time period:**

The data has been selected for different time periods. We have selected the records from the year 2006/07 till 2018/19.

1.
  1. **Components**
    1. **Feeding the Data: Fetch()**

 def fetch\_data(surround\_config): dir\_path = surround\_config.get\_path(&quot;surround.path\_to\_epl\_data&quot;) all\_files = glob.glob(dir\_path + &quot;/\*.csv&quot;)

df\_from\_each\_file = (pd.read\_csv(f) for f in all\_files)
input\_data = pd.concat(df\_from\_each\_file, ignore\_index=True, sort=False)
return input\_data

In EPL match prediction `fetch_data` starts by directing the path of `surround_config` to epl data. path\_to\_epl\_data: ../data/epl\_csv ``Then it grabs all the data from that set path in this case the csv files. Afterwards the csv files are converted into dataframes. In the process of converting these files to dataframes, the index of each file is ignored which in terms gives us theepl\_datawhich is ourinput\_data`.

1.
  1. **Wrangling ()**

To create different Modulues and frameworks stages( ) are used and it also has multiple classes

It extends the stage class and acts as a skelton for other classess

    class WranglingData(Stage):

       def \_\_init\_\_(self):
      self.processed\_data = pd.DataFrame()

#### let us see different functions involving Wranglingdata(stage)

There are 4 Functions which are used in Wranglingdata(stage) ##### clean\_empty\_data def clean\_empty\_data(self): self.processed\_data.dropna(inplace=True)

This function clean the row containing empty field, that means this function deletes the row in the data folder if it contains any empty field. Remove the row with the missing value of any attributes.

##### **Categorical\_team\_to\_ordinal\_value**

    def categorical\_team\_to\_ordinal\_value(self, team):
    elite\_team = [&quot;&quot;&quot;&#39;Man United&#39;&quot;&quot;&quot;, &#39;Liverpool&#39;, &#39;Arsenal&#39;, &#39;Chelsea&#39;, &#39;Tottenham&#39;]
    semi\_elite\_team = [&quot;&quot;&quot;&#39;Man City&#39;&quot;&quot;&quot;, &#39;Everton&#39;, &quot;&quot;&quot;&#39;Aston Villa&#39;&quot;&quot;&quot;, &#39;Newcastle&#39;, &#39;Wolves&#39;]
    pro\_team = [&quot;&quot;&quot;&#39;Nottingham Forest&#39;&quot;&quot;&quot;, &#39;Blackburn&#39;, &quot;&quot;&quot;&#39;Sheffield Wednesday&#39;&quot;&quot;&quot;, &#39;Sunderland&#39;,
              &quot;&quot;&quot;&#39;Leeds United&#39;&quot;&quot;&quot;]
    semi\_pro\_team = [&quot;&quot;&quot;&#39;West Brom&#39;&quot;&quot;&quot;, &quot;&quot;&quot;&#39;West Ham&#39;&quot;&quot;&quot;, &quot;&quot;&quot;&#39;Sheffield United&#39;&quot;&quot;&quot;, &#39;Leicester&#39;, &#39;Portsmouth&#39;]

This categorical\_team to ordinal value is used tp convert log value in the data tables to integer value and This function assign the rank of each team.

##### **Normalize\_data**

 def normalize\_data(self):
 columns\_to\_standardize = [[&#39;HomeTeam&#39;, &#39;AwayTeam&#39;, &#39;HS&#39;, &#39;AS&#39;, &#39;HST&#39;, &#39;AST&#39;, &#39;HF&#39;, &#39;AF&#39;, &#39;HC&#39;, &#39;AC&#39;, &#39;HR&#39;, &#39;AR&#39;]]

   for each\_col in columns\_to\_standardize:
      self.processed\_data[each\_col] = normalize(self.processed\_data[each\_col])

This function normalizes the features on the columns\_to\_normalize. that means in the data obtained for data prediction the values for some of the matches are too high and for some its too low,to make it between (0-1) the data is normailzed. This process can be useful if you plan to use a quadratic form such as the dot-product or any other kernel to quantify the similarity of any pair of samples.

##### **Shift\_column**

    def shift\_column(self):
     temp\_store = self.processed\_data.pop(&#39;FTR&#39;)
     self.processed\_data[&#39;FTR&#39;] = temp\_store


This function shift column from middle to the last of the dataframe, for the training and testing purpose where 30 of it is testing and 70% is training. The training set contains a known output and the model learns on this data in order to be generalize to other data later on. We have the test dataset (or subset) in order to test our model&#39;s prediction on this subset.

1.
  1. **Modeling and Prediction()**

**Introduction:**

The main purpose of this stage is to perform prediction task on the provided data frames. This stage consists of five different functions.

1. 1) **Initializing Function:**

![Init](https://raw.githubusercontent.com/Shibi8/Surround\_AI\_Suqad\_2/master/Images/init.png)

The  def \_\_init\_\_() function  initializes the two different variables for the data frames. One variable is for the processed data, which is in the streamline and the other is for the data frame on which the prediction function will be implemented.

1. 2) **Combining Results Function:**

![Combine](https://raw.githubusercontent.com/Shibi8/Surround\_AI\_Suqad\_2/master/Images/combine.png)

This function performs the task of combining multiple testing data subsets of the original dataset and then display the output as the predicted value.

1. 3) **Prediction Report Function:**

![PredictRepo](https://raw.githubusercontent.com/Shibi8/Surround\_AI\_Suqad\_2/master/Images/predict.png)

This function provides performance metrics and other metrics reports for the corresponding prediction models. This function predicts the total number of win for a particular team. It takes into account the total number of home and away wins to predict the result.

Furthermore, the function build a confusion matrix of home win, away wins &amp; draw matches and takes the mean of the home wins in real and predicted results.

1. 4) **Train Test Data Function:**

![TrainTest](https://raw.githubusercontent.com/Shibi8/Surround\_AI\_Suqad\_2/master/Images/TrainTest.png)

The main purpose of this function is to split the datasets into two categories i.e. training and testing datasets into defined ration for further processing. The datasets has been divided as 70% training and 30% testing data.  We have utilized logistic regression for our predictive analysis. Here, the test data set is utilized to test the model in consideration to examine its accuracy.

1. 5) **Operate Function:**

![Operate](https://raw.githubusercontent.com/Shibi8/Surround\_AI\_Suqad\_2/master/Images/operate.png)

This function is used to operate processed input data from a datasets onto a resulting output data matrix.

1. **DisplayOutput**

**DataOutput(Stage)** is the final stage in the surround framework. It comes after the stage DataModeling and works as the name suggests. The purpose of this stage is to show the final output of the processed data in the framework. For the example EPL match prediction, the final output of the data can be shown as either of the following \* Graph \* Table

The DataOutput(Stage) can be farther broken down to three different parts.

### Display\_histogram

def display\_histogram(self, histo\_data, output\_dir):

        fig1, ax = plt.subplots(1, 2)
        histo\_data.FTR.value\_counts().plot(&quot;bar&quot;, ax=ax[0]).set\_title(&quot;Real&quot;)
        histo\_data.Predicted\_FTR.value\_counts().plot(&quot;bar&quot;, ax=ax[1]).set\_title(&quot;Predicted&quot;)
        plt.show()

        fig1.savefig(output\_dir + &quot;/compare\_result.png&quot;)
        plt.close()

From the code we can see that plt is the called function matplotlib.pyplot which is responsible for plotting the histogram. And the histo\_data is the data derived from the previous classes to graphically represent the predection bars. The output we get from display\_histogram is given below.

![](https://raw.githubusercontent.com/Sikbatullah/Surround\_AI\_Suqad\_2/master/epl/output/compare\_result.png)

### Prediction\_report

def prediction\_report(self, real, prediction, output\_dir):
        h = 0
        a = 0
        d = 0
        for x in prediction:
            if x == &quot;H&quot;:
                h = h + 1
            elif x == &quot;A&quot;:
                a = a + 1
            else:
                d = d + 1
        print(&quot;Total home win: {0}&quot;.format(h))
        print(&quot;Total away win: {0}&quot;.format(a))
        print(&quot;Total draw: {0}&quot;.format(d))

        labels = [&quot;H&quot;, &quot;D&quot;, &quot;A&quot;]
        cnf\_matrix = metrics.confusion\_matrix(real, prediction, labels)
        print(cnf\_matrix)
        print(&quot;The accuracy of the Logistic regression model is: {0}&quot; .format(metrics.accuracy\_score(real, prediction)))

        df\_confusion = pd.DataFrame(cnf\_matrix, index=[&quot;Home Win&quot;, &quot;Draw&quot;, &quot;Away Win&quot;], columns=[&quot;Predicted Home Win&quot;, &quot;Predicted Draw&quot;, &quot;Predicted Away Win&quot;])

        fig2 = plt.figure(2)
        sns.heatmap(df\_confusion, annot=True, cbar=False)
        fig2.savefig(output\_dir + &quot;/confusion\_matrix.png&quot;)
        plt.show()

From the code above we can see that sns is the called function for seaborn which is responsible for plotting the confusion matrix. The confusion matrix compares the real data with the predicted data. Here H represents home win, A represents Away win and D represent the chances of draw between two teams.

![](https://raw.githubusercontent.com/Sikbatullah/Surround\_AI\_Suqad\_2/master/epl/output/confusion\_matrix.png)

### Operate

``` def operate(self, surround\_data, config): output\_dir = config.get\_path(&quot;surround.path\_to\_output&quot;) surround\_data.result\_data.to\_csv(output\_dir + &quot;/test\_output.csv&quot;)

    self.display\_histogram(surround\_data.result\_data, output\_dir)
    self.prediction\_report(surround\_data.result\_data.FTR, surround\_data.result\_data.Predicted\_FTR, output\_dir)
    print(&quot;It&#39;s fine up to here.&quot;)

``` Operate is responsible changing saving the predictive out test cases to the output folder in csv formats. It is also resposnible for the plotting and saving histograms along with plotting confusion matrix and saving the files.

1. **Features Utilized of Surround:       **

### 1. Modular Programming:

Division of a program/class into sub-classes and testing separately makes it easy to read, maintain and rely upon. When a modular system is created, several modules are built separately and more or less independently. The executable application will then be created by putting them together. In other words, Every file, which has the file extension .py and consists of proper Python code is a module. There is no special syntax required to make such a file a module. Usually, modules contain functions or classes, but there can be &quot;plain&quot; statements in them as well. These statements can be used to initialize the module. They are only executed when the module is imported.

### 2. Re-usability of code (Stages)

1. Same code can be used in other code to perform specific functionality as the code is divided into stages.
2. Stage is an implementation of data transformation. Here is the place SurroundData is altered to accomplish the outcome that you need. Each stage is just meant to execute a set of related actions. First stage can be where you get ready information to be processed and last stage can be the place your populate information to be sent back to the client.

### 3. Easier Access to Data (SurroundData)

1. SurroundData is a sharable item between stages that holds vital data for each stage. A stage will read some data from SurroundData, process it, then at that point set back new data that will be utilized by different stage(s). When you expand this class, you can include as many number of variables as you require to enable you to change input data into output data. In any case, there are 4 center factors that are being utilized.

- **stage\_metadata** is information that can be used to identify a stage.
- **execution\_time** is recorded time to complete a process.
- **errors** is information to identify failure of a stage.
- **warnings** is information when transformation is not 100% right.

1.   class SVRData(SurroundData):

  def \_\_init\_\_(self):
  self.dta = pd.DataFrame()


  def get\_data(self):
  self.dta = pd.read\_csv(&#39;config.yaml&#39;)
  self.dates = []
  self.prices = []
  self.x = [self.prices]

### 4. Surround(): creates Pipeline

1. It is a group of numerous stages or just an initial stage to change raw information into meaningful data. You can set the order of stages directly or by means of a config file. The config file enables you to characterize more than 1 pipeline execution and after that you can switch between them effectively.
2. A file is created with extension .surround to create a project in the pipeline.

-   project-info:
    project-name: svr

### 5. Config.yaml can be configured in the start for the whole project, Global variable, methods

1. Path to data - &#39;Surround\_AI\_Suqad\_2/svr/data/AAPL.csv&#39;
2. An example from Apple Stock Price Predictions

- class SVRData(SurroundData):
- def **init** (self): self.dta = pd.DataFrame()
- def get\_data(self): self.dta = pd.read\_csv(&#39;config.yaml&#39;) self.dates = [] self.prices = [] self.x = [self.prices]

config.yaml

output:
text: Hello World

image: svr
company: yourcompany
version: latest

#Details of class inheriting from Wrapper
wrapper-info: svr.wrapper.PipelineWrapper

surround:
path: &#39;../data/AAPL.csv&#39;

1. YAML is a human-readable data serialization format that takes concepts from Python, ideas from XML and the data format of electronic mail. The configuration file is written in Python code and saved separately. The config.yaml file can be called/read from within a code.





1. **Drawbacks/ Limitations of Surround:**

#### Importing packages:

When you create a python File with class or function and you need to use it somewhere in another file,then you must important the package that you want to use, when tried with command line using python 3, it throws excess. Necessity of use of operate function in every class is yet to be clarified.

#### Plotting graphs

While plotting the graphs It was not directly popping-up new window rather it was showing error, but for surround data visualization is very important, Its drawback is in that its default style isn&#39;t always visually appealing, and it can be complex to make the adjustments according to the data.

#### Conclusion

Surround is framework for machine learning pipelines in python which helps to understand the problem easily, Surround consists of group of stages or a single stage which transforms raw data into meaning full data using layers of filters. Each task is performed in each pipeline which makes the data flow easy, where data can be easily manipulated and accessed around the project, Surround helps in managing error handling as it focus on only a single stage rather than the whole part. It has the flexibility for re-usability of code(stages) as the used code can be reused to perform a different function as the code is divided into stages. There are so many merits of surround as it can used anywhere as it makes the understanding very clear and It divides the program or class into sub-classes and testing separately makes it easy to read, maintain and rely upon. It is very easy to access to data that surround data where it is sharable item between that holds data for each stage